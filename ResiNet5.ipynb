{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1g-asPrBS_ld87JAyQKCmvv-0BuCVnt2w",
      "authorship_tag": "ABX9TyOmGlw/0eGfqyllLKgYd/Oi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sg0107/CNN/blob/main/ResiNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from drive.MyDrive.w2a1.Files.tf.W2A1.resnets_utils import *\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "\n",
        "from drive.MyDrive.w2a1.Files.tf.W2A1.test_utils import summary, comparator\n",
        "import drive.MyDrive.w2a1.Files.tf.W2A1.public_tests as public_tests\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)"
      ],
      "metadata": {
        "id": "PH7ZM_KOWfj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, f, filters, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path.\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### START CODE HERE\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    ## Set the padding = 'same'\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same',kernel_initializer = initializer(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    ## Set the padding = 'valid'\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid',kernel_initializer = initializer(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X) # Default axis\n",
        "\n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "TyBf1VWca0xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: convolutional_block\n",
        "\n",
        "def convolutional_block(X, f, filters, s = 2, initializer=glorot_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer,\n",
        "                   also called Xavier uniform initializer.\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "\n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "\n",
        "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "j_7aDDe0bnaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: ResNet50\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 6, training=False):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Use the instructions above in order to implement all of the Stages below\n",
        "    # Make sure you don't miss adding any required parameter\n",
        "\n",
        "    ## Stage 3 (≈4 lines)\n",
        "    # `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
        "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
        "\n",
        "    # the 3 `identity_block` with correct values of `f` and `filters` for this stage\n",
        "    X = identity_block(X, 3, [128,128,512])\n",
        "    X = identity_block(X, 3, [128,128,512])\n",
        "    X = identity_block(X, 3, [128,128,512])\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
        "    X = convolutional_block(X, f = 3, filters = [256,256,1024], s = 2)\n",
        "\n",
        "    # the 5 `identity_block` with correct values of `f` and `filters` for this stage\n",
        "    X = identity_block(X, 3, [256,256,1024])\n",
        "    X = identity_block(X, 3, [256,256,1024])\n",
        "    X = identity_block(X, 3, [256,256,1024])\n",
        "    X = identity_block(X, 3, [256,256,1024])\n",
        "    X = identity_block(X, 3, [256,256,1024])\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    # add `convolutional_block` with correct values of `f`, `filters` and `s` for this stage\n",
        "    X = convolutional_block(X, f = 3, filters = [512,512,2048], s = 2)\n",
        "\n",
        "    # the 2 `identity_block` with correct values of `f` and `filters` for this stage\n",
        "    X = identity_block(X, 3, [512,512,2048])\n",
        "    X = identity_block(X, 3, [512,512,2048])\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D()(X)\"\n",
        "    X= AveragePooling2D()(X)\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7tGXv7ipch0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.set_learning_phase(True)\n",
        "\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "DWwEww7NdjKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### you cannot edit this cell\n",
        "\n",
        "from drive.MyDrive.w2a1.Files.tf.W2A1.outputs import ResNet50_summary\n",
        "\n",
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "\n",
        "comparator(summary(model), ResNet50_summary)\n"
      ],
      "metadata": {
        "id": "9TfGe-03dmvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0015)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "blCQa2XddtoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('/content/drive/MyDrive/w2a1/Files/tf/W2A1/datasets/train_signs.h5', \"r\")\n",
        "    test_dataset = h5py.File('/content/drive/MyDrive/w2a1/Files/tf/W2A1/datasets/test_signs.h5', \"r\")\n",
        "\n",
        "    X_train_orig = train_dataset[\"train_set_x\"][:]\n",
        "    Y_train_orig = train_dataset[\"train_set_y\"][:]\n",
        "    X_test_orig = test_dataset[\"test_set_x\"][:]\n",
        "    Y_test_orig = test_dataset[\"test_set_y\"][:]\n",
        "    classes = train_dataset[\"list_classes\"][:]\n",
        "\n",
        "    train_dataset.close()\n",
        "    test_dataset.close()\n",
        "\n",
        "    return X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes\n"
      ],
      "metadata": {
        "id": "Aje-nC6Uoe6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig / 255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNq3PWqzeBaV",
        "outputId": "7e134865-bc8b-4d3e-d292-d42a8ac26ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
      ],
      "metadata": {
        "id": "l9A8vn07ppP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "id": "MTINidpRrgJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = load_model('/content/drive/MyDrive/w2a1/Files/tf/W2A1/resnet50.h5')"
      ],
      "metadata": {
        "id": "1TpiWOWssaVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = pre_trained_model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "metadata": {
        "id": "tnJeFIoosozU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/photo.jpg'\n",
        "img = image.load_img(img_path, target_size=(64, 64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = x/255.0\n",
        "x2 = x\n",
        "print('Input image shape:', x.shape)\n",
        "imshow(img)\n",
        "prediction = pre_trained_model.predict(x2)\n",
        "print(\"Class prediction vector [p(0), p(1), p(2), p(3), p(4), p(5)] = \", prediction)\n",
        "print(\"Class:\", np.argmax(prediction))\n"
      ],
      "metadata": {
        "id": "4yNicOmVsrKW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}